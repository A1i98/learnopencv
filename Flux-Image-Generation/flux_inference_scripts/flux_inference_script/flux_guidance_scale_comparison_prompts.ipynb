{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff9ef62-f5ec-49c8-8472-5615d27a7185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U diffusers -q\n",
    "!pip install transformers==4.43.2 -q\n",
    "!pip install accelerate -q\n",
    "!pip install sentencepiece -q\n",
    "!pip install protobuf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a921496e-620e-40ff-8ca2-812160cf2ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fe238ad3c54d20a17001e95d1022cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c18092b-33de-4c97-8a26-173e3013537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "The token `flux_token2` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `flux_token2`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c6301-699c-4dee-9f9e-404163e0dba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b806758fd7f4420481f3867acacdadc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/536 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fffe048cc6420e960bee605426492a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 23 files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b607f3465946aba02b9efb116e3e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c743e9ec154a97844ff7f60fa1ae78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)t_encoder_2/model.safetensors.index.json:   0%|          | 0.00/19.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22725543529749d8baabc78960872500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2/config.json:   0%|          | 0.00/782 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82db494475cc4a95ac14e1375a14bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/273 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1be54c5d114a0db4f180e2afac428c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dee2b959a3c47368157bd52cad3ba85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0d2eec5ba6489ba2b4c18b2d5d7014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5972307bfa4615a7111b8f10c7b345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746225e7782f499489921a8686e9f8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a541df016444e80af9d5860014df4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f559a9a19d4d4a8d25edf94142efa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca8a48572eb446ca4687b32484a7d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e94e9d2e944b47ae1adfab3d49b97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762651bfe12740dca6fb455913e02dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9905c77fc744f6b8db25d3ae1095a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/config.json:   0%|          | 0.00/378 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0214b62a4c544b488ec9e99b3e29659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe0bcdca0c447fba34e055774a20be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)pytorch_model-00002-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f46319c2ce40af9bb272e728f51fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)pytorch_model-00001-of-00003.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd479c6b0f74e70b818b2196b990e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ion_pytorch_model.safetensors.index.json:   0%|          | 0.00/121k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e619af4c14a85babd42dbb8fa7dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)pytorch_model-00003-of-00003.safetensors:   0%|          | 0.00/3.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c204dcf5c51846b18775203b26f58b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/820 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284c3a8d388a445695e829d3f615aa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d51e586836a4b84ac204daa1a170cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6eef3356a54fb1ba2b23f9c4b1aede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype = torch.bfloat16)\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b1d86-e62b-4eb7-923e-9d09b862a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FluxPipeline {\n",
       "  \"_class_name\": \"FluxPipeline\",\n",
       "  \"_diffusers_version\": \"0.31.0\",\n",
       "  \"_name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"FlowMatchEulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5TokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"FluxTransformer2DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4cda76-47c6-4fce-9337-9dfb3076bf65",
   "metadata": {},
   "source": [
    "**Guidance Scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df1c0b8-3bb3-41d0-a8b9-888fd53c8a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67425966c724600b3dd2836c9e8f58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light, this candid moment of street life has been preserved.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ab44be-c5d9-4ca4-95cc-7c3d3d6ba7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['has been preserved.']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bc1f261d8d404ea36430dd3906bb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light, this candid moment of street life has been preserved.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street1__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543fc04-6877-47e4-885e-1e5ca0a9bba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e6e6a-1764-4b2f-a742-7fc6eacc1f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e017893-eb62-4f32-b9a6-840c0bf828ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['has been preserved.']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32508a109b7431f93e98657e00a2c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light, this candid moment of street life has been preserved.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02fe1b72-eaee-4ba2-b8e2-8c46f3566c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['has been preserved.']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bbffd4771c4fafbc9e9141fdd9ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light, this candid moment of street life has been preserved.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street2__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b7ed1-9c0a-4ee3-9a19-a4679bcdea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7072c-0f33-4e00-ac7d-8e9be1059f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd438486-0ff5-4cc8-8265-feb4611f9876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f39a5f21a34f0880b67953cded544f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b50d63-ce5b-4a7f-9ec3-ba04ec464502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f21ccee82746f6ac1fce21dd55a786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street3__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a091a99-528d-4fcc-9ffd-e9013c903633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b64191-ab7e-49f7-ab9e-ed7237cf368f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8c9565-58b1-49f8-9dc4-bf3dbc067580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f78d7b479943af961003aa98fb12f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50d18e22-9880-44e9-ae23-38425152b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800c590f77774de2973dcb810b5301c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street4__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a40e23-15b2-4e23-91f3-82fc1883ba6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ae1e0-67e1-4b26-8ec7-464dee42b4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893d7ee5-4fe6-49ed-9ffd-492ed2b87f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee0ee2a4674455d8646b915bf4cf4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb78575f-66d1-40b4-a466-865a76a2e54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb4ed4f67b848699f7f3b24702da435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street5__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2b259-a126-4f73-a8c8-0c28a830db12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2879c-dbf0-4991-ac06-7a28b57b8e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4cb09e0-e769-478f-b33a-7eba082a0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9b97d3188848c69dc4247f6aed67cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "526c598a-4c67-4a1b-8db2-adbf596ed090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f070a4f813d54998a1f66348d87082b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street6__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a75233-091d-40a0-9db8-33bbfd049df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459822e-b535-4876-8934-b3bc1242fd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c386c7c-4559-4b2f-b6b6-384bd7478270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f0537ae25148ff9e85801325a43b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f45350b4-98f5-4372-8698-9f6823f0db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6153b03372924abea2bca75ebc90608c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street7__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e33b8-d44e-48cf-bc22-c726db7b4028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263dbe1-a883-43e1-b7f4-d636b369284c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b963d9-fdb8-47bd-aed1-ef3fb4a07b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c05562c6b84722b794dd9b7fb16578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street8.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "110467be-877a-4571-8c0d-95d0a3ec7370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c1dc1c5e29441b9f272ffc2c766198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Black-and-white street photography of an old woman sitting alone on a street bench, as people walking past her are blurred due to a slow shutter speed, emphasising her loneliness and isolation from society. \n",
    "Captured with a Nikon D850, a wide-angle lens, an aperture of f/4, and soft natural light.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-street8__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcd8fa-fa9e-4b05-9998-59065a45b8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067a382-5d6d-433e-8e83-3c78499851d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c7e87-ebdc-4edf-899d-d6c081133009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be3828-bd19-4be4-9e4e-26d6c960237d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bfc29b-4cec-4830-a39d-41c6a7c91127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd13d6-ac20-4ae2-8aa9-50bb7ba09730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eb1edcc-6efd-4006-80d2-81e2909a2c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f487723440fb4e70ac402b63380e6440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "440da672-d9eb-409a-b898-b23f80c3a7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d95c8121b6445049c2d7e3b54f570d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene1__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0436a-35cf-4db9-a8eb-642e5a4fa937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025a3ea-78bb-4d06-858c-e6e61f49b4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e172832-e780-4ffb-a340-f3b7b8ed9166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398f1048ef8743acbecf34ac0b06901e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3614690d-0e66-4f7c-9a33-90cd4e939dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621170ea0e814f08848eb81521190a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=1.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene2__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac019df4-924c-48bd-b0df-5e86f3e0246c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca1783-2e55-44a9-9064-ea8c8102265e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e65019e6-13ad-4974-9a83-d6c29848cca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d292a056054b55abb10d8b34b21900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47e8eca8-099d-4f19-bb8b-34893e9b59a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140d2bc9345643dbb49370cbd163ed43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene3__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f9852-752b-4c3e-8e20-9693eed2bffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b020d9-fad6-49ff-9f45-094156af3e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd16710-9ca1-4afe-95f6-2461a02fb768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e24b9b367c49699462931f6b550be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b58d6a1-5b51-42c4-94a9-129fed8b6113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2233c7ea749f4cfeaa7e518f533ea678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene4__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8651510-267f-4914-afa2-f01369ce540d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f9ecd-86e5-4495-85e2-4d27ea1af86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "841054bf-e2d9-4262-bd1c-e7d3de1ae9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6415b13c51134e6e8d3402a4ddcff457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "935dfb0b-bf27-4209-ad5b-4d69fc1f818d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee263f1f83b404da79f8021bee05632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene5__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984203e-a235-4ad3-ab35-609cfafdc419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf94cb-73f6-408e-8757-8e43a55ede38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00c2d688-fc24-4bd4-8c4e-b7ccda74310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e742be504cc414db83d73579f8f31fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95b150d1-cc71-4d26-a886-145e4c102cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee08de83d9f42ff92f4895df020b97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=3.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene6__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c90f1-ecc3-4116-ac29-f29f9e5ff6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed48a1f-b0c3-49c2-a71f-3842a0c168ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdbe2d5f-e25e-44c1-a3d8-c64e06ebe3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588c9997cce94d0b9dcca122dbc16e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.0,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c65eaebc-b4f0-43aa-9d88-9bbaa4a55505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14c53d00e20403e8c1a8abc723d82b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.0,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene7__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21421ce-f67c-43eb-b293-1a6e2ae146b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d410a-0722-48b0-a612-c99bbd39ba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08f7f308-31c0-4770-a94d-0979daec675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2676ff51d6824adb9aa4eab3b75ca50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.5,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene8.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b0a0378-9d37-47d7-80a4-073f164cbb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f914b9efd648b1bf208d8f430d49a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\" Generate an oil painting of a tranquil lakeside at sunset. \n",
    "The scene includes mountains in the background, reflections on the water, and a small wooden boat near the shore. \n",
    "Emphasize warm colors like orange, pink, and purple.\"\"\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=4.5,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-scene8__.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf17001-d02c-464d-b565-cd3fa5bba1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29254a14-c686-4375-9fae-d0c087fac811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce653c82-9fee-42d2-853a-8f3ced4657cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e70987-e278-4aca-a078-59782abf349b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
