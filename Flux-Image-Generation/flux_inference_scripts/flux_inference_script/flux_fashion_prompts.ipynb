{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f773f9a-ff48-4232-8477-990a2e159bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U diffusers -q\n",
    "!pip install transformers==4.43.2 -q\n",
    "!pip install accelerate -q\n",
    "!pip install sentencepiece -q\n",
    "!pip install protobuf -q\n",
    "!pip install matplotlib -q\n",
    "!pip install pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0db6f28-fbf5-4ab6-a401-c49828787c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f67dba7be414c4db9e010345f03e7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d32a9d6-a381-4589-b69f-4254661a513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "The token `flux_token2` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `flux_token2`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef08630-61fa-4e27-a102-997f462c0c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c289b8fbb6754d268a84c1cd5ab953b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/536 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b5430490e44804bd9bd61e934c0051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 23 files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddff2cecde84307887959dbba564208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1644386c521487fa60231e41e4ea964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21141c1a52b041daaf07db43e4d5fd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2/config.json:   0%|          | 0.00/782 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65435cd91c2c417888a0c15b0b144336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fc180d965647d1be504f5a845368f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/273 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f534dd3fd05462ab4a889284b5a9ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)t_encoder_2/model.safetensors.index.json:   0%|          | 0.00/19.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7caf9b7da046f2a535b977d8976dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f542874aa2e44df1b04461bcb067cd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee57cafda1541afae725f58a55cc290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a1b45f5932425c878fd2b6395b58a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8382b6ed31b849cd81bd59095a90cbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abf60229c02409ca4f34ab0044bce9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e1a892759e474c9d7a2aa93413b8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e0c7cad02746b6a740649b67d1cc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3ec2f49e8240b2836a25b1a8274d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eca231424e408cacfc2ca398ea3555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/config.json:   0%|          | 0.00/378 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae03e12006d4b5c80dbecdb26662be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)pytorch_model-00001-of-00003.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8545baf538241bf86a01b23dae6daa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)pytorch_model-00002-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10ba6e4be4d48ff994c3ab152cf5c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ion_pytorch_model.safetensors.index.json:   0%|          | 0.00/121k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c623289c84447887269229edc6b7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)pytorch_model-00003-of-00003.safetensors:   0%|          | 0.00/3.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3cf7972fb24da0b5103249e8509eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/820 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7861ef97c1ed4b5ca170bf3babb28dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123529cf89594bca9a3df650c3a069a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f607921009c4489aa0dce474dc68e8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466f78d0-4908-4227-9285-9dc2186b4623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FluxPipeline {\n",
       "  \"_class_name\": \"FluxPipeline\",\n",
       "  \"_diffusers_version\": \"0.31.0\",\n",
       "  \"_name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"FlowMatchEulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5TokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"FluxTransformer2DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a2f08e-d118-4ea6-9715-6e261a4a58e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ebdb0d2bae431cbb119ed3d956a402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Elegant evening gown with intricate details, luxurious\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_fashion1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed07b24-b305-45f8-8386-4a5aa2e3f1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef06189b764b62ba93c003fb8815e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Elegant evening gown with intricate details, luxurious\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_fashion2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4749b3-2665-4604-84bf-6d940a3599b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccdf57b380741f28f24cdd7858a54c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Casual streetwear look with comfortable and cool vibe\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_fashion3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1653686-77d5-4dc3-8092-f60396c43ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935ee76ef25643e7a087974767230173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Casual streetwear look with comfortable and cool vibe\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_fashion4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1b2d53-d9a7-4d76-b444-4746192bdd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47484464cee041289979465f98b48b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Vintage-style movie poster of a noir detective, dark alley, rain-soaked streets, 1940s aesthetic.\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=30_movie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602e01b1-3a84-4d6d-b1d6-0bc0fd7fd6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d951cfb9ea4bd5a1308bc87fabfaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Vintage-style movie poster of a noir detective, dark alley, rain-soaked streets, 1940s aesthetic.\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_movie2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5d8e5d2-c8b0-4c0e-bb4b-6e63d827c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52af633e447341b5a9cf0be1c635031c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \" Horror movie poster, haunted house, eerie fog, ghostly figure, 1970s horror film style.\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=30_movie3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1734af5b-434f-4ee9-be62-d63dcd38b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ab0ee592b04d56a038c1dbf38dc3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \" Horror movie poster, haunted house, eerie fog, ghostly figure, 1970s horror film style.\"\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_movie4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9780ad7-f249-45a2-a5b0-03007c05e769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (237 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['allowing the subject to command the spotlight. the stage radiates with dramatic lighting, as spotlights cut through the velvety haze of smoke, creating a dynamic and immersive atmosphere. employing the iconic rembrandt lighting technique, the musician â€™ s face and hands are skillfully bathed in soft, directional light, accentuating every passionate expression and intricate movement. harnessing the powerful midjourney v 5 with photorealism mode, this image transcends mere representation, vividly capturing the musician â€™ s unwavering talent and boundless devotion. with each strum of the guitar, the viewer becomes entranced by the artist â€™ s undeniable passion, transported to a realm where music becomes a living, breathing entity. â€“ v 5. 2 â€“ ar 1 6 : 9 â€“ style raw']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef448d8f2ab49b6a1a679683fd55f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Step into a captivating portrait capturing the essence of a musician, their fingers dancing across the strings of a guitar on a vibrant stage. \n",
    "Through the lens of a Sony Î±7 III camera, equipped with a 100mm lens set to a wide-open aperture of F 1.2, the background seamlessly dissolves into a tapestry of artful bokeh, allowing the subject to command the spotlight. \n",
    "The stage radiates with dramatic lighting, as spotlights cut through the velvety haze of smoke, creating a dynamic and immersive atmosphere. \n",
    "Employing the iconic Rembrandt lighting technique, the musicianâ€™s face and hands are skillfully bathed in soft, directional light, accentuating every passionate expression and intricate movement. \n",
    "Harnessing the powerful Midjourney v5 with photorealism mode, this image transcends mere representation, vividly capturing the musicianâ€™s unwavering talent and boundless devotion. \n",
    "With each strum of the guitar, the viewer becomes entranced by the artistâ€™s undeniable passion, transported to a realm where music becomes a living, breathing entity. â€“v 5.2 â€“ar 16:9 â€“ style raw\"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_guitarist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c9131f4-c194-4077-930d-7123fa659543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['allowing the subject to command the spotlight. the stage radiates with dramatic lighting, as spotlights cut through the velvety haze of smoke, creating a dynamic and immersive atmosphere. employing the iconic rembrandt lighting technique, the musician â€™ s face and hands are skillfully bathed in soft, directional light, accentuating every passionate expression and intricate movement. harnessing the powerful midjourney v 5 with photorealism mode, this image transcends mere representation, vividly capturing the musician â€™ s unwavering talent and boundless devotion. with each strum of the guitar, the viewer becomes entranced by the artist â€™ s undeniable passion, transported to a realm where music becomes a living, breathing entity. â€“ v 5. 2 â€“ ar 1 6 : 9 â€“ style raw']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b64cbb83374ef6b3a73d74c486521a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Step into a captivating portrait capturing the essence of a musician, their fingers dancing across the strings of a guitar on a vibrant stage. \n",
    "Through the lens of a Sony Î±7 III camera, equipped with a 100mm lens set to a wide-open aperture of F 1.2, the background seamlessly dissolves into a tapestry of artful bokeh, allowing the subject to command the spotlight. \n",
    "The stage radiates with dramatic lighting, as spotlights cut through the velvety haze of smoke, creating a dynamic and immersive atmosphere. \n",
    "Employing the iconic Rembrandt lighting technique, the musicianâ€™s face and hands are skillfully bathed in soft, directional light, accentuating every passionate expression and intricate movement. \n",
    "Harnessing the powerful Midjourney v5 with photorealism mode, this image transcends mere representation, vividly capturing the musicianâ€™s unwavering talent and boundless devotion. \n",
    "With each strum of the guitar, the viewer becomes entranced by the artistâ€™s undeniable passion, transported to a realm where music becomes a living, breathing entity. â€“v 5.2 â€“ar 16:9 â€“ style raw\"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=30_guitarist2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aff55ecd-5306-4a0a-9009-02aefe120db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['between the traditional and the modern, the old and the new. use a high - resolution 1 6 k camera with a 1 6 : 9 aspect ratio, a raw style, and a quality setting of 2. â€“ ar 1 6 : 9 â€“ v 5. 1 â€“ style raw']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eefbf99abc24912a4d747beef990994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Picture an elderly Indian woman, her gray hair contrasting with her vibrant green saree, as she tries to navigate her way around a smartphone. \n",
    "A young child in a red t-shirt and blue shorts is trying to explain the device to her. The setting is a rural Indian campus, surrounded by mango, palm, and coconut trees and blooming flowers. \n",
    "The image should capture the contrast between the traditional and the modern, the old and the new. \n",
    "Use a high-resolution 16k camera with a 16:9 aspect ratio, a raw style, and a quality setting of 2. â€“ar 16:9 â€“v 5.1 â€“style raw\"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=30_elderly.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ba7ae7e-d916-4f5a-aa45-08f178899061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['between the traditional and the modern, the old and the new. use a high - resolution 1 6 k camera with a 1 6 : 9 aspect ratio, a raw style, and a quality setting of 2. â€“ ar 1 6 : 9 â€“ v 5. 1 â€“ style raw']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1f89e010694563bc9d563ba787ce7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Picture an elderly Indian woman, her gray hair contrasting with her vibrant green saree, as she tries to navigate her way around a smartphone. \n",
    "A young child in a red t-shirt and blue shorts is trying to explain the device to her. The setting is a rural Indian campus, surrounded by mango, palm, and coconut trees and blooming flowers. \n",
    "The image should capture the contrast between the traditional and the modern, the old and the new. \n",
    "Use a high-resolution 16k camera with a 16:9 aspect ratio, a raw style, and a quality setting of 2. â€“ar 16:9 â€“v 5.1 â€“style raw\"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_elderly2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db0fcf64-361f-4718-b97b-6d2fbe177b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['soft lighting, volumetric, conte - jour, global illumination, screen space global illumination, scattering, shadows, rough, shimmering, lumen reflections, screen space reflections, diffraction grading, chromatic aberration, gb displacement, scan lines, ambient occlusion, anti - aliasing, fkaa, txaa, rtx, ssao, opengl - shader â€™ s, post processing, post - production, cell shading, tone mapping, cgi, vfx, sfx, insanely detailed and intricate, hyper maximalist, elegant, dynamic pose, photography, volumetric, ultra - detailed, intricate details, super detailed, ambient â€“ ar 1 6 : 9 â€“ v 5. 2 â€“ style raw']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4189597a060b485696bd9a9ebcca5e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Portrait of Indian village woman at a gathering in the forests of Himachal Pradesh , Cinematic, Photoshoot, Shot on 25mm lens, Depth of Field, Tilt Blur, Shutter Speed 1/1000, F/22, White Balance, 32k, Super-Resolution, Pro Photo RGB, Half rear Lighting, Backlight, Dramatic Lighting, Incandescent, Soft Lighting, Volumetric, Conte-Jour, Global Illumination, Screen Space Global Illumination, Scattering, Shadows, Rough, Shimmering, Lumen Reflections, Screen Space Reflections, Diffraction Grading, Chromatic Aberration, GB Displacement, Scan Lines, Ambient Occlusion, Anti-Aliasing, FKAA, TXAA, RTX, SSAO, OpenGL-Shaderâ€™s, Post Processing, Post-Production, Cell Shading, Tone Mapping, CGI, VFX, SFX, insanely detailed and intricate, hyper maximalist, elegant, dynamic pose, photography, volumetric, ultra-detailed, intricate details, super detailed, ambient â€“ar 16:9 â€“v 5.2 â€“style raw\"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_elderly3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6540bb52-47d0-44f9-9104-152187f4afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['of 2 to capture this panoramic view. â€“ ar 1 6 : 9 â€“ v 5. 2 â€“ style raw â€“ q 2 â€“ s 7 5 0']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fe9368bb1f4e06b67185fd1f96e15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Visualize a cityscape from a birdâ€™s eye view, showcasing the cityâ€™s architectural diversity and urban layout. \n",
    "The image should capture the cityâ€™s sprawling expanse, the variety of buildings, and the intricate network of streets. \n",
    "Use a high-resolution 16k camera with a 16:9 aspect ratio, a raw style, and a quality setting of 2 to capture this panoramic view. â€“ar 16:9 â€“v 5.2 â€“style raw â€“q 2 â€“s 750 \"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=30,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=30_cityscape.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f6bf76-685e-479b-a054-c3d57913005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['of 2 to capture this panoramic view. â€“ ar 1 6 : 9 â€“ v 5. 2 â€“ style raw â€“ q 2 â€“ s 7 5 0']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc3b8f295804a668a6297ab182bb7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Visualize a cityscape from a birdâ€™s eye view, showcasing the cityâ€™s architectural diversity and urban layout. \n",
    "The image should capture the cityâ€™s sprawling expanse, the variety of buildings, and the intricate network of streets. \n",
    "Use a high-resolution 16k camera with a 16:9 aspect ratio, a raw style, and a quality setting of 2 to capture this panoramic view. â€“ar 16:9 â€“v 5.2 â€“style raw â€“q 2 â€“s 750 \"\"\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=2.7,\n",
    "    num_inference_steps=50,\n",
    "    max_sequence_length=512,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ").images[0]\n",
    "image.save(\"flux-dev-gs=2.7_nis=50_cityscape2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05eb7d9-ee86-4eba-b3e1-9d6b92a5c407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
