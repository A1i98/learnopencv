{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and initializing a V-env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda create -n matanyone python=3.13 -y\n",
    "%conda activate matanyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloning and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pq-yang/MatAnyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MatAnyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e .\n",
    "!pip3 install -r hugging_face/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing directories for structured folder arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping video as per your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_pt = 'input_path'\n",
    "output_video_pt = 'input_name.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = int()\n",
    "end_time = int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(input_video_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter(output_video_pt, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frame = int(start_time * fps)\n",
    "end_frame = int(end_time * fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_frame = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    print(\"working...\")\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    if start_frame <= current_frame <= end_frame:\n",
    "        out.write(frame)\n",
    "    current_frame += 1\n",
    "    # print(current_frame)\n",
    "    if current_frame > end_frame:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"successfuly completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating masks for the first frame using SAM2\n",
    "(The script given below can be executed without running clipping and changing directories section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAM(\"sam2.1_b.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('input_path')\n",
    "# _ ,image = vidcap.read() \n",
    "# num = 51\n",
    "# for i in range(int(num)):\n",
    "ret ,image = vidcap.read() \n",
    "    # if i == 49:\n",
    "cv2.imwrite(\"output_name\", image)  \n",
    "      \n",
    "success,image = vidcap.read()\n",
    "print('First Frame Extraction: ', success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and saving all the binary masks of the objects in the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"input_path\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img, project = \"save_dir_path\", save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id, result in enumerate(results):\n",
    "    # print(result)\n",
    "    for mask_id, mask_tensor in enumerate(result.masks.data):\n",
    "        # if mask_id == 10:\n",
    "        \n",
    "            mask_np = mask_tensor.cpu().numpy()\n",
    "            binary_mask = (mask_np > 0.5).astype(np.uint8) * 255\n",
    "        \n",
    "            print(type(binary_mask), binary_mask.shape)\n",
    "            filename = f\"binary_mask_name_{mask_id}.jpg\"\n",
    "            cv2.imwrite(filename, binary_mask)\n",
    "            print(f\"Saved {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = cv2.imread(\"./binary_mask3_1.jpg\")\n",
    "# img2 = cv2.imread(\"./binary_mask3_4.jpg\")\n",
    "# img3 = cv2.imread(\"./binary_mask3_5.jpg\")\n",
    "# # img4 = cv2.imread(\"./binary_mask3_3.jpg\")\n",
    "# # img5 = cv2.imread(\"./binary_mask3_4.jpg\")\n",
    "# # img6 = cv2.imread(\"./binary_mask3_5.jpg\")\n",
    "# # img7 = cv2.imread(\"./binary_mask3_6.jpg\")\n",
    "# # img8 = cv2.imread(\"./binary_mask3_7.jpg\")\n",
    "# img4 = cv2.add(img1, img2)\n",
    "# img5 = cv2.add(img4, img3)\n",
    "# # img7 = cv2.add(img6, img4)\n",
    "# # img12 = cv2.add(img11, img5)\n",
    "# # img13 = cv2.add(img12, img6)\n",
    "# # img14 = cv2.add(img13, img7)\n",
    "# # img15 = cv2.add(img14, img8)\n",
    "# cv2.imwrite(\"im5.jpg\", img5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing MatAnyone with max_size argument set to 1080\n",
    "(The script given below can be executed without running clipping, generating with SAM2, and changing directories section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If running on kaggle the below section is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda create -n matanyone python=3.13 -y\n",
    "%conda activate matanyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below script needs to bw executed to perform inferencing on MatAnyone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference_matanyone.py -i /kaggle/input/mat-anyone/matanyone_sample_video_2.mp4 -m /kaggle/input/mat-anyone/binary_mask_img0_mask3.png --max_size=1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6758689,
     "sourceId": 10881482,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "its_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
