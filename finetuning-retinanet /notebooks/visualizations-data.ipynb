{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaab361f",
   "metadata": {},
   "source": [
    "## Notebook for Data Annotation Visualization\n",
    "\n",
    "A simple notebook for visualizing ground truth data with the annotated bounding booxes.\n",
    "\n",
    "Change the image and annotation path as per your dataset directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c7d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b190f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.path.join(\n",
    "    '..',\n",
    "    'data',\n",
    "    'test',\n",
    "    'images'\n",
    ")\n",
    "annotation_paths = os.path.join(\n",
    "    '..',\n",
    "    'data',\n",
    "    'test',\n",
    "    \"labels_converted\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d5336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"angle\", \"fracture\", \"line\", \"messed_up_angle\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "318a1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(os.path.join(image_paths, '*.jpg'))\n",
    "annotations = glob.glob(os.path.join(annotation_paths, '*.txt'))\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Randomize in same order.\n",
    "random.Random(42).shuffle(images)\n",
    "random.Random(42).shuffle(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b44217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(txt_path, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Reads bounding box annotations from the new PyTorch format (txt files) and\n",
    "    denormalizes them to absolute pixel values.\n",
    "\n",
    "    Expected Format (Normalized):\n",
    "        <class_id> <x_min> <y_min> <x_max> <y_max>\n",
    "    \n",
    "    :param txt_path: Path to the annotation text file\n",
    "    :param image_width: Width of the corresponding image\n",
    "    :param image_height: Height of the corresponding image\n",
    "    :return: boxes (list of [x_min, y_min, x_max, y_max]), labels (list of class names)\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        values = line.strip().split()\n",
    "        if len(values) != 5:\n",
    "            print(f\"Skipping malformed line in {txt_path}: {line}\")\n",
    "            continue  # Skip incorrect entries\n",
    "        \n",
    "        class_id = int(values[0])\n",
    "        x_min, y_min, x_max, y_max = map(float, values[1:])\n",
    "        \n",
    "        # Denormalize coordinates by multiplying with image width & height\n",
    "        x_min = int(x_min * image_width)\n",
    "        y_min = int(y_min * image_height)\n",
    "        x_max = int(x_max * image_width)\n",
    "        y_max = int(y_max * image_height)\n",
    "\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "        labels.append(CLASSES[class_id])  # Convert class ID to class name\n",
    "\n",
    "    return boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31f2fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize first 10 images (already shuffled)\n",
    "for data_num, (image_path, annotation_path) in enumerate(zip(images, annotations)):\n",
    "    # Read Image\n",
    "    image = cv2.imread(image_path)\n",
    "    img_h, img_w = image.shape[:2]\n",
    "\n",
    "    # Read Annotations\n",
    "    boxes, labels = read_annotations(annotation_path, img_w, img_h)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    for i, box in enumerate(boxes):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        class_name = labels[i]\n",
    "        color = COLORS[i % len(COLORS)]  # Cycle through colors\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(x_min),int(y_min)),\n",
    "            (int(x_max), int(y_max)),\n",
    "            color=color,\n",
    "            thickness=3,\n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        cv2.putText(\n",
    "            image,\n",
    "            text=class_name,\n",
    "            org=(x_min, max(20, y_min - 7)),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.8,\n",
    "            color=color,\n",
    "            thickness=2,\n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    # Show image with bounding boxes\n",
    "    plt.title(os.path.basename(image_path))  # Display filename\n",
    "    plt.imshow(image[:, :, ::-1])  # Convert BGR to RGB for Matplotlib\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if data_num == 9:  # Stop after 10 images\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a1aa5-be5b-4efa-a72c-1d8323bd163b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
